version: '3.8'

services:
  # Development environment
  dev:
    build:
      context: .
      target: development
    volumes:
      - .:/app
      - ./data:/app/data
      - ./outputs:/app/outputs
      - ./checkpoints:/app/checkpoints
    environment:
      - PYTHONUNBUFFERED=1
      - TRANSFORMERS_CACHE=/app/.cache/huggingface
    command: /bin/bash
    stdin_open: true
    tty: true
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  # Training service
  train:
    build:
      context: .
      target: production
    volumes:
      - ./data:/app/data
      - ./outputs:/app/outputs
      - ./config:/app/config
    environment:
      - PYTHONUNBUFFERED=1
      - TRANSFORMERS_CACHE=/app/.cache/huggingface
    command: python src/finetune.py --config config/training_config.yaml
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  # TensorBoard service
  tensorboard:
    image: tensorflow/tensorflow:latest
    volumes:
      - ./outputs:/app/outputs
    ports:
      - "6006:6006"
    command: tensorboard --logdir=/app/outputs/runs --host=0.0.0.0

  # Inference service
  inference:
    build:
      context: .
      target: production
    volumes:
      - ./outputs:/app/outputs
    ports:
      - "8000:8000"
    environment:
      - PYTHONUNBUFFERED=1
      - TRANSFORMERS_CACHE=/app/.cache/huggingface
    command: python src/inference.py --model_path outputs/final_model
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

